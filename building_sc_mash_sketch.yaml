name: Build a mash sketch database of all fungal genomes in RefSeq

on:
  workflow_dispatch:
    inputs:
      refseq_version:
        description: 'Enter the RefSeq version to use as a tag (e.g. v230, v231, etc.)'
        required: true

jobs:
  # --------------------------------------------------------------------------
  # JOB 1: Use a manually currated list of genomes, sc_ids.tsv
  # --------------------------------------------------------------------------
 
  list_genomes:
    runs-on: ubuntu-latest
    steps:
      - name: Check Out Repository
        uses: actions/checkout@v4

      - name: Use the manually provided genome list
        run: |
          # Check if the manual file exists in the repository
          if [ ! -f "sc_ids.tsv" ]; then
            echo "ERROR: sc_ids.tsv not found in the repository."
            exit 1
          fi
          # Copy the manual list to the name the next job expects
          cp sc_ids.tsv
          echo "Using manually curated list of genomes."

      - name: Split id list for parallel jobs
        run: |
          split -n l/10 sc_ids.tsv -d --additional-suffix=.tsv x

      - name: Upload list chunks for next job
        uses: actions/upload-artifact@v4
        with:
          name: genome-chunks
          path: x*.tsv
          overwrite: true

# The below lines are if accession numebrs are being pulled from NCBI, if a custom ids.txt list was manually currated, leave lines commented out and use above code
      #- name: Download NCBI Datasets Tool
      #  run: |
      #    wget -q https://ftp.ncbi.nlm.nih.gov/pub/datasets/command-line/v2/linux-amd64/datasets
      #    chmod +x datasets

      #- name: Get Fungal Genome List
      #  run: |
      #    export PATH=$(pwd):$PATH
      #    ./datasets summary genome taxon 4751 --reference --as-json-lines | \
      #    jq -r '[.accession, .organism.organism_name] | @tsv' > ids.tsv

      #- name: Check list size
      #  id: check_size
      #  run: |
      #    count=$(wc -l < ids.tsv)
      #    echo "Found ${count} fungal genomes."
      #    echo "count=${count}" >> $GITHUB_OUTPUT

      #- name: Split id list for parallel jobs
      #  run: |
      #    split -n l/10 ids.tsv -d --additional-suffix=.tsv x

      #- name: Upload list chunks for next job
      #  uses: actions/upload-artifact@v4
      #  with:
      #    name: genome-chunks
      #    path: x*.tsv
      #    overwrite: true

  # --------------------------------------------------------------------------
  # JOB 2: Create sketches for each chunk in parallel
  # --------------------------------------------------------------------------
  create_sketches:
    needs: list_genomes
    runs-on: ubuntu-latest
    timeout-minutes: 720 # 12 hours
    strategy:
      fail-fast: false
      matrix:
        chunk: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
    steps:
      - name: Download Tools
        run: |
          wget -q https://ftp.ncbi.nlm.nih.gov/pub/datasets/command-line/v2/linux-amd64/datasets
          chmod +x datasets
          wget -q https://github.com/marbl/Mash/releases/download/v2.3/mash-Linux64-v2.3.tar
          tar -xvf mash-Linux64-v2.3.tar && mv mash-Linux64-v2.3/mash .

      - name: Download genome chunk artifact
        uses: actions/download-artifact@v4
        with:
          name: genome-chunks
      
      - name: Download, Unzip, and Sketch Genomes (Chunk ${{ matrix.chunk }})
        run: |
          export PATH=$(pwd):$PATH
          INPUT_FILE=$(printf "x%02d.tsv" ${{ matrix.chunk }})
          OUTPUT_SKETCH="chunk_${{ matrix.chunk }}.msh"

          echo "Processing ${INPUT_FILE} one genome at a time..."
          
          while IFS=$'\t' read -r accession organism_name; do
            if [ -z "$accession" ]; then continue; fi

            echo "--- Processing $accession ---"
            mkdir -p temp_genome_files
            
            success=false
            for i in 1 2 3; do
              if ./datasets download genome accession "$accession" --no-progressbar --filename "temp_genome_files/genome.zip"; then
                success=true
                break
              fi
              echo "Download attempt $i for $accession failed. Retrying in 15s..."
              sleep 15
            done

            if ! $success; then
              echo "ERROR: Failed to download $accession after 3 attempts. Skipping."
              rm -rf temp_genome_files
              continue
            fi

            unzip -q -o temp_genome_files/genome.zip -d temp_genome_files/unzipped
            fasta_file=$(find temp_genome_files/unzipped -name "*.fna")

            if [ -z "$fasta_file" ] || [ ! -f "$fasta_file" ]; then
                echo "ERROR: Could not find .fna file for $accession. Skipping."
                rm -rf temp_genome_files
                continue
            fi
            
            ./mash sketch -k 21 -s 1000 -p 8 -o temp_genome_files/single.msh "$fasta_file"
            
            if [ ! -f "$OUTPUT_SKETCH" ]; then
              mv temp_genome_files/single.msh "$OUTPUT_SKETCH"
            else
              mv "$OUTPUT_SKETCH" temp_chunk.msh
              ./mash paste "$OUTPUT_SKETCH" temp_chunk.msh temp_genome_files/single.msh
              rm temp_chunk.msh
            fi
            
            rm -rf temp_genome_files
            
          done < "$INPUT_FILE"

      - name: Upload partial sketch artifact
        uses: actions/upload-artifact@v4
        with:
          name: partial-sketch-${{ matrix.chunk }}
          # === THIS IS THE CORRECTED LINE ===
          # Directly provide the filename that the previous step creates.
          path: chunk_${{ matrix.chunk }}.msh
          overwrite: true

  # --------------------------------------------------------------------------
  # JOB 3: Combine all partial sketches (Corrected Download Logic)
  # --------------------------------------------------------------------------
  combine_sketches:
    # This job will run even if some of the sketching jobs from the matrix failed
    if: success() || failure()
    needs: create_sketches
    runs-on: ubuntu-latest
    steps:
      - name: Download Mash
        run: |
          wget -q https://github.com/marbl/Mash/releases/download/v2.3/mash-Linux64-v2.3.tar
          tar -xvf mash-Linux64-v2.3.tar && mv mash-Linux64-v2.3/mash .
      
      - name: Download all created sketch artifacts
        uses: actions/download-artifact@v4
        with:
          # By NOT specifying a 'name', this action downloads ALL artifacts from this workflow run.
          # The artifacts are placed into subdirectories named after the artifact.
          path: partial_sketches/
      
      - name: Combine all sketches
        run: |
          export PATH=$(pwd):$PATH
          FINAL_SKETCH_NAME="Fungi_RefSeq_${{ github.event.inputs.refseq_version }}.msh"
          echo "Pasting all downloaded partial sketches into ${FINAL_SKETCH_NAME}..."

          # Check if the directory with sketches exists and is not empty
          if [ ! -d "partial_sketches" ] || [ -z "$(ls -A partial_sketches)" ]; then
            echo "No sketch artifacts were downloaded. Cannot create final database."
            exit 1
          fi
          
          # The 'find' command will locate all .msh files within the downloaded artifact subdirectories
          ./mash paste "$FINAL_SKETCH_NAME" $(find partial_sketches -name "*.msh")

      - name: Compress final sketch
        run: |
          FINAL_SKETCH_NAME="Fungi_RefSeq_${{ github.event.inputs.refseq_version }}.msh"
          gzip "$FINAL_SKETCH_NAME"

      - name: Create Release and Upload Final Sketch
        uses: softprops/action-gh-release@v2
        with:
          name: Fungal RefSeq Database ${{ github.event.inputs.refseq_version }}
          tag_name: ${{ github.event.inputs.refseq_version }}
          files: Fungi_RefSeq_${{ github.event.inputs.refseq_version }}.msh.gz
